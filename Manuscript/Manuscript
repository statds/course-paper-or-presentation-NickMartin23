\documentclass[12pt]{article}

%% preamble: Keep it clean; only include those you need
\usepackage{amsmath}
\usepackage[margin = 1in]{geometry}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{setspace}

% for space filling
% highlighting hyper links
\usepackage[colorlinks=true, citecolor=blue]{hyperref}


%% meta data

\title{2023 An Analysis of this Year in Music}
\author{Nicholas Martin\\
  University of Connecticut
}

\doublespacing

\begin{document}
\maketitle

\begin{abstract}
In 2023 the music industry remains more divided than ever before, yet as a society we grow more and more connected each year through outlets like the internet or social media. What is the explanation for this? Most believe that with the progression of technology comes the ability to streamline information and media. An individual's ability to consume music looks much different nowadays than it did in the 1960’s. Streaming platforms have basically made it so that any child with a cellphone has access to millions of songs for free. A stark contrast from the earlier 20th centuries’ vinyl format. It is because of this evolution in media consumption that most people believe the charts are so segmented. With the internet people don't have to subject themselves to Pop radio in order to hear music. Specific tastes and sub genres can be discovered easily using Spotify for example; a streaming service that even recommends specific songs based on what you’ve already listened to. People's taste in music has become so specific this way. Now anyone is able to find songs and artists that exactly match their music taste regardless of the popularity of that artist. It is in this explanation that I hold a lot of stock in explaining why Billboard's 2023 Year End Top 100 songs chart contains such a variation of artists, and why the content of the songs on it vary as well. There is so much information that we can surmise by examining these year end lists. And although it may seem arbitrary, a lot of this information is being used in full effect by the music industry, not only to predict the popularity of the music, but as well to learn more about ourselves as a species and the way we’ve consumed media over time.
\end{abstract}


\section{Introduction}
\label{sec:intro}
For the purposes of this statistical analysis my main goal is simple. I aim to explore the use of statistical models in order to predict musical trends for the year 2023. For this task I am using the year end top100 list from Billboard and I am using data from RouteNote for the variables I will be using. I chose this particular topic since it pertains to me greatly as a musician and music listener. But these types of studies are deeply important in finding out more about ourselves and our habits over time. It is of course very important for people who are a part of the music industry as well. Because of this, prior research has of course been done on this topic generally extensively. People have been using chart data for years to predict trends. This is a popular practice for the boardroom category of song writing. However, It is with the year almost at its end that I turn my focus to 2023, where I will use data from the year in order to predict a song's potentially chart position. I will start off by examining the data, after which I will use General Linear Regression in order to create some models for the project. Finally I aim to use song data from other years to predict how well a track would’ve done on the chart in 2023.\\

% roadmap
The rest of the paper is organized as follows.
The data will be presented in Section~\ref{sec:data}.
The methods are described in Section~\ref{sec:meth}.
The results are reported in Section~\ref{sec:resu}.
A discussion concludes in Section~\ref{sec:disc}.

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Chart Position & Artist 2 & Track Length & BPM & Energy & Valence \\
    \hline
    1 & Morgan Wallen & 2:43 & 203.853 & 67.5 & 51.8 \\
    2 & Miley Cyrus & 3:20 & 118.048 & 69.1 & 63.2 \\
    3 & SZA & 2:33 & 88.993 & 72.8 & 43 \\
    4 & Taylor Swift & 3:20 & 97.008 & 64.3 & 53.3 \\
    5 & Metro Boomin & 3:41 & 97.95 & 60.8 & 15.2 \\
    6 & Rema & 3:59 & 106.999 & 80.6 & 80.2 \\
    7 & The Weeknd & 4:20 & 133.349 & 52.5 & 51 \\
    8 & Luke Combs & 4:25 & 97.994 & 60.3 & 67 \\
    9 & SZA & 3:21 & 143.008 & 55.1 & 39.2 \\
    10 & David Guetta & 2:55 & 128.04 & 96.5 & 30.4 \\
    \hline
  \end{tabular}
  \caption{Head of 2023 top 100 Data}
  \label{T100Head}
\end{table}

\section{Data}
\label{sec:data}

For the actual track list that I will be using to make my predictions I am using the 2023 Billboard top 100 year end chart. Billboard basically has taken into account all aspects of each song's performance. This includes: airplay, sales, and jukebox activity aswell; which includes streams. Billboard then creates a point system which typically gives sales more weight than the other variables as purchases of a song are a great indicator that that song is particularly popular. And from their point system Billboard compiles the year end statistics for 2023; the song with the most streams and sales and airplay gets the first spot and the other 99 most popular songs of the year comprise the rest of the list. It is an extremely useful and regulated tool to get popular song data from. And it is important to note that Billboard compiles their data across all genres. For the actual music data that I will be using I have enlisted the help of RouteNote which is an extremely useful tool that calculates data based on individual songs. This data includes several variables including: track length, BPM, and key. The song dataset that I will be working with contains 6 columns; 5 independent variables and a dependent variable. It contains the year end chart position for each song on the 2023 Billboard chart, artist name, bpm, track length, energy coefficient and valence coefficient. All of the variables that I have acquired from RouteNote are gathered using Spotify’s AI which uses machine learning in order to determine metadata on a particular song.\\

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Artist & & Track Length & BPM & Energy & Valence \\
    \hline
    Morgan Wallen - 8 & Min. & 109 & 67.2 & 9.1 & 3.9 \\
    SZA - 4 & 1st Qu. & 176.8 & 106.4 & 51.5 & 33.55 \\
    Drake - 3 & Median & 196.5 & 129 & 61.9 & 51.05 \\
    Luke Combs - 3 & Mean & 196.8 & 127.6 & 62.21 & 50.94 \\
    Taylor Swift - 3 & 3rd Qu. & 222 & 145.2 & 74.25 & 67.33 \\
    Bailey Zimmerman - 2 & Max. & 277 & 203.9 & 96.5 & 96.1 \\
    \hline
  \end{tabular}
  \caption{Summary of Top 100 Data}
  \label{Summary}
\end{table}

In order to conduct the model building segment of our statistical analysis latter we must encode the categorical variable within this dataset so that when we use Rstudio we can perform linear regression. Similarly I have converted the track length variable which is in format (M:SS) into a numerical value representing how long each song is in seconds. Further summarizing the data will tell us more even more information. We can see that it was a particularly good year for Morgan Wallen who had 8 songs on the Billboard charts this year doubling second places SZA. We can predict that the artist variable may have significant pull when it comes to our final model; as it definitely payed to be Morgan Wallen in 2023.\\

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{Histogram1.pdf}
  \caption{Histograms of Independent Variables}
  \label{fig:Hist1}
\end{figure}

I have plotted histograms for the four numeric variables in our dataset and the results are as shown. We can see the individual distributions for Track Length, BPM, Energy, and Valence. As we can see from the plots, none of these distributions look particularly bad. We can see that they all roughly display normality, and there are no bars that extend abnormally far away from the rest of the distribution. Similarly we can see that no bars in any of the Histograms hang abnormally tall; this suggests no existence of any outliers within our dataset. This is important information because it means that we can now check 

\begin{figure}[h]
  \centering
  \includegraphics[width=0.8\textwidth]{Scatterplot1.pdf}
  \caption{Scatterplots of Independant Variables}
  \label{fig:Scatterplot1}
\end{figure}

As We can see from each of the scatter-plots our variables do not appear to have any initial correlation with that of the dependant variable chart position. We've determined this as there is notable randomness in each of the plots and there is no apparent positive or negative trend that we can see visually. There are however small exceptions that can be found in the plot of Track Length, and Energy; Note the subtle pattern that may be examined among the points. A small positive correlation can potentially be seen in both casenerios. In order to further confirm these findings I have gone ahead and used the correlation function in Rstudio so as to determine these variables relationship with the dependent.

\begin{table}
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    Track Length & BPM & Energy & Valence \\
    \hline
    0.06836279 & 0.02202227 & -0.04396084 & 0.1356192 \\
    \hline
  \end{tabular}
  \caption{Correlation Coeficient of Numeric Variables}
  \label{CorrCoef}
\end{table}

The correlation coefficients that we've gotten for each of the variables support the thoughts from our scatter-plots. the coefficients remain generally close to zero which could determine no correlation in some case. This could also suggest using transformations, such as a log transformation, in order to more accurately present the relationship that a particular variable has with the chart position dependant variable. The correlation between Valence and chart position remains the highest at 0.1356192. This could suggest potentially that songs that have a higher valence (Sound Happier; i.e Major Keys) would be more likely to chart. I have also gone ahead and conducted tests for multicolinearity as to check the predictors for any particularly strong correlation. This step is important, otherwise we may run into some problems down the road with respects to estimating the coefficients and interpreting our results.\\

\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|c|c|}
    \hline
    & Track Length & BPM & Energy & Valence \\
    \hline
    Track Length & 1.00000000 & -0.01009661 & -0.07279693 & -0.1971547 \\
    BPM & -0.01009661 & 1.00000000 & 0.05436178 & 0.1333351 \\
    Energy & -0.07279693 & 0.05436178 & 1.00000000 & 0.3307796 \\
    Valence & -0.19715467 & 0.13333511 & 0.33077959 & 1.0000000 \\
    \hline
  \end{tabular}
  \caption{Multicolinearity Check of Numeric Variables}
  \label{Correlation Matrix}
\end{table}

Concluding this exploratory analysis of the data we can feel generally confident in all of the information collected. And in looking at the histogram and scatterplots, as well as the correlation coefficients we can safely determine that the best course of action for us is Ordinal Regression. For our purposes the incorporation of ordinal regression makes the most sense because the chart position variable is ordinal, with rankings from 1-100. In order for us to use ordinal regression to model our data we must first confirm the assumptions of ordinal regression. These assumptions are included in table 5.

\section{Methods}
\label{sec:meth}

\begin{table}[t]
  \centering
  \begin{tabular}{|c|}
    \hline
      - Assumptions - \\
    \hline
     The dependant variable is measured on an ordinal  level\\
     One or more of the predictor variables are continuous, categorical or ordinal \\
     No Multicollinearity \\
     Proportional Odds \\
    \hline
  \end{tabular}
  \caption{Assumptions of Ordinal Regression}
  \label{Assumptions}
\end{table}

In order to confirm the assumption of zero multicollinearity we turn our attention to table 4. It is here where we can see what looks to be quite promising results. As is recorded, none of the correlation coefficients have an absolute value $> 0.7$ which is a rough confirmation that there is no multicollinearity present amongst the predictor variables. And in confirming the other assumptions of ordinal regression we find similar success. As I've already described, the dependent variable does indeed have an ordinal structure, as well, we are using one or more continuous, categorical, or ordinal variables. We can similarly confirm that each independent variable has an identical effect across all points of the ordinal dependent variable.\\

With the assumptions of ordinal regression confirmed we may begin to model our data. I have gone ahead and used the polr function in Rstudio as to properly format our ordinal regression. For this first model, I have included the artists variable as well, as this will give us coefficients and relevant information for each artist in 2023. 



\section{Results}
\label{sec:resu}




\section{Discussion}
\label{sec:disc}

What are the main contributions again?

What are the limitations of this study?

What are worth pursuing further in the future?


\bibliography{refs}
\bibliographystyle{plain}

\end{document}
